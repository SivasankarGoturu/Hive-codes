Partitioning
==============================================
Static partitioning 
------------------------------------------

create table orders_w_partition(
id string,
customerid string,
productid string,
quantity string,
amount double,
zipcode char(5)
)
Partitioned by (state char(2))
row format delimited
fields terminated by ',';

describe formatted orders_w_partition;

load data local inpath '/home/cloudera/Downloads/Hiveadv1/order_ca.csv'
into table orders_w_partition Partition (state="CA");

load data local inpath '/home/cloudera/Downloads/Hiveadv1/order_ct.csv'
into table orders_w_partition Partition (state="CT");


List no.of partitions
-----------------
show partitions orders_w_partition;


Dynamic partitions
======================================
Enable dynamic partitions
----------------------------
SET hive.exec.dynamic.partition=true;
SET hive.exec.dynamic.partition.mode=nonstrict;


step1 Create table with no partitions

create table orders_no_partition(
id string,
customerid string,
productid string,
quantity string,
amount double,
zipcode char(5),
state char(2)
)
row format delimited
fields terminated by ',';

load data local inpath '/home/cloudera/Downloads/Hiveadv1/orders_CA_with_state.csv'
into table orders_no_partition;

load data local inpath '/home/cloudera/Downloads/Hiveadv1/orders_CT_with_state.csv'
into table orders_no_partition;

load data local inpath '/home/cloudera/Downloads/Hiveadv1/orders_NY_with_state.csv'
into table orders_no_partition;



step2 Create table with partitions



create table orders(
id string,
customerid string,
productid string,
quantity string,
amount double,
zipcode char(5)
)
Partitioned by (state char(2))
row format delimited
fields terminated by ',';


Step3 Load data from partitioned to non partitioned table 

insert into orders
partition (state)
select * from orders_no_partition;


Bucketing
=======================================================

SET hive.enforce.bucketing=true;

Step 1 create a table withot bucketing
---------------------------------------------------------------------

create table products_no_bucketing(
id string,
name string,
cost double,
category string
)
row format delimited
fields terminated by ',';


Step2 load data
---------------------------------------------------------------------

load data local inpath '/home/cloudera/Downloads/Hiveadv1/newprodu*'
into table products_no_bucketing;

Step3 create table with bucketing
---------------------------------------------------------------------

create table products_w_bucketing(
id string,
name string,
cost double,
category string
)
clustered by (id) into 4 buckets;


Step 4 insert data into non bucketing table to bucketing table 
---------------------------------------------------------------------

insert into products_w_bucketing
select * from products_no_bucketing;




Partitioning two columns
======================================================================

Step1 Create non partitioned table 
-------------------------------------------------------------------


create table orders_no_partition1(
orderid string,
customerid string,
productid string,
quantity int,
proce float,
zipcode int,
country string,
state string
)
row format delimited
fields terminated by ',';


Step2 Load data
-------------------------------------------------------------------


load data local inpath '/home/cloudera/Downloads/Hiveadv1/orders_country_w_states.csv' 
into table orders_no_partition1;


Step3 Create partitioned table
-------------------------------------------------------------------


create table all_orders(
orderid string,
customerid string,
productid string,
quantity int,
proce float,
zipcode int
)
partitioned by (country string, state string)
row format delimited fields terminated by ',';


Step 4 Load data from non partitioned table to partitioned table
-------------------------------------------------------------------
insert into table all_orders
partition (country,state)
select * from orders_no_partition1;



Partition on multiple columns

create table all_orders2(
orderid string,
customerid string,
quantity int,
proce float,
zipcode int
)
partitioned by (country string, state string, productid string)
row format delimited fields terminated by ',';


Can we alter datatype for hive table?
Load data without normal table in both dynamic partition and bucketing


Partitioning with bucketing
=====================================================================
Step 1 Normal table
------------------------------------------------------------

create table products_no_buckets(
id int,
product string,
cost float,
category string
)
row format delimited
fields terminated by ',';

Step 2 Load data
----------------------------------------------------------------

load data local inpath '/home/cloudera/Downloads/Hiveadv1/newproducts.csv' 
into table products_no_buckets;


Step 3 partitioned table with bucketing
------------------------------------------------------------------
create table products_partitioned_buckets(
id int,
product string,
cost float
)
partitioned by (category string)
clustered by (id) into 4 buckets
row format delimited
fields terminated by ',';


Step 4 Load data from non part to part
-----------------------------------------------------------------
insert into table products_partitioned_buckets
partition (category)
select * from products_no_buckets;




Join Optimization
===================================================================
===================================================================

Import 2 tables into hdfs from mysql using sqoop


sqoop import \
--connect jdbc:mysql://localhost:3306/retail_db \
--username retail_dba \
--password cloudera \
--table orders \
--warehouse-dir /user/cloudera/Joinoptimization


sqoop import \
--connect jdbc:mysql://localhost:3306/retail_db \
--username retail_dba \
--password cloudera \
--table customers \
--warehouse-dir /user/cloudera/Joinoptimization

create database joinoptimization;


Create two external tables
======================================================================
CREATE external TABLE orders(
order_id int,
order_date string,
order_customer_id int,
order_status string)
row format delimited 
fields terminated by ',' 
stored as textfile location '/user/cloudera/Joinoptimization/orders';


CREATE external TABLE customers(
customer_id int,
customer_fname string,
customer_lname string,
customer_email string,
customer_password string,
customer_street string,
customer_city string,
customer_state string,
customer_zipcode string) 
row format delimited 
fields terminated by ',' 
stored as textfile location '/user/cloudera/Joinoptimization/customers';



Auto convert properties
------------------------------------------------------------

hive.auto.convert.join;
set hive.auto.convert.join=false;
set hive.auto.convert.join=true;


set false then run query, it will invoke reduce job
-------------------------------------------------------------------
SELECT c.customer_id, c.customer_fname, c.customer_lname, o.order_id, o.order_date FROM orders o 
JOIN customers c ON (o.order_customer_id = c.customer_id) limit 10;


Set the hint manually to invoke map side join
===================================================
set hive.auto.convert.join=false; 
set hive.ignore.mapjoin.hint;
set hive.ignore.mapjoin.hint = false;


Use Inner join
----------------------------------------------------

SELECT /*+ MAPJOIN(o) */ c.customer_id, c.customer_fname, c.customer_lname, o.order_id, 
o.order_date FROM orders o
JOIN customers c ON (o.order_customer_id = c.customer_id) limit 5;

Use Left outer join **it Through error
--------------------------------------------------------

SELECT /*+ MAPJOIN(o) */ c.customer_id, c.customer_fname, c.customer_lname, 
o.order_id, o.order_date FROM orders o 
LEFT OUTER JOIN customers c ON (o.order_customer_id = c.customer_id) limit 5;


Use right outer join 
--------------------------------------------------------

SELECT /*+ MAPJOIN(o) */ c.customer_id, c.customer_fname, c.customer_lname, 
o.order_id, o.order_date FROM orders o 
RIGHT OUTER JOIN customers c ON (o.order_customer_id = c.customer_id) limit 5;


Use full outer join 
--------------------------------------------------------

SELECT /*+ MAPJOIN(o) */ c.customer_id, c.customer_fname, c.customer_lname, 
o.order_id, o.order_date FROM orders o 
FULL OUTER JOIN customers c ON (o.order_customer_id = c.customer_id) limit 5;



Small file size
====================================

hive.mapjoin.smalltable.filesize;



Bucket Map join
===================================================
===================================================

CREATE external TABLE customers_bucketed(customer_id int,
customer_fname string,
customer_lname string,
customer_email string,
customer_password string,
customer_street string,
customer_city string,
customer_state string,
customer_zipcode string) 
clustered by(customer_id) into 4 buckets 
row format delimited 
fields terminated BY ',';

insert into customers_bucketed 
select * from customers;



CREATE external TABLE orders_bucketed(order_id int,
order_date string,
order_customer_id int,
order_status string) 
clustered by(order_customer_id) into 8 buckets 
row format delimited 
fields terminated BY ',';


insert into orders_bucketed 
select * from orders;


There is a property
-----------------------------------------
set hive.optimize.bucketmapjoin
set hive.optimize.bucketmapjoin = true;



SELECT c.customer_id, c.customer_fname, c.customer_lname, o.order_id, 
o.order_date FROM customers_bucketed c 
JOIN orders_bucketed o ON (c.customer_id = o.order_customer_id) limit 10;




Sort Merge Bucket Join (SMB)
===============================================
===============================================

DROP TABLE ORDERS_BUCKETED;
DROP TABLE CUSTOMERS_BUCKETED;


Set below properties
--------------------------------------------------

set hive.auto.convert.sortmerge.join=true;
set hive.auto.convert.sortmerge.join.noconditionaltask=true;
set hive.optimize.bucketmapjoin=true;
set hive.optimize.bucketmapjoin.sortedmerge=true;
set hive.enforce.bucketing=true;
set hive.enforce.sorting=true;
set hive.auto.convert.join=true;



CREATE TABLE customers_bucketed(customer_id int,
customer_fname string,
customer_lname string,
customer_email string,
customer_password string,
customer_street string,
customer_city string,
customer_state string,
customer_zipcode string) 
clustered by(customer_id) 
sorted by(customer_id asc) into 4 buckets 
row format delimited 
fields terminated BY ',';



insert into customers_bucketed select * from customers;


CREATE TABLE orders_bucketed(order_id int,
order_date string,
order_customer_id int,
order_status string) 
clustered by(order_customer_id) 
sorted by(order_customer_id asc) into 4 buckets 
row format delimited 
fields terminated BY ',';


insert into orders_bucketed select * from orders;


Window Functions
=================================================

create table groceries(id string,  
store string,  
product string,  
day date,  
revenue double) 
row format delimited 
fields terminated by ',';


load data local inpath '/home/cloudera/Downloads/Hiveadv1/groceries.csv' 
into table groceries;


To get running sum of groceries table - order by id:
----------------------------------------------------------
from groceries select id, revenue, day, sum(revenue) 
over (order by id rows between unbounded preceding and current row) as running_total;

+-----+----------+-------------+----------------+--+
| id  | revenue  |     day     | running_total  |
+-----+----------+-------------+----------------+--+
| 10  | 4.0      | 2017-01-06  | 4.0            |
| 11  | 5.0      | 2017-01-05  | 9.0            |
| 12  | 4.0      | 2017-01-07  | 13.0           |
| 13  | 5.0      | 2017-01-07  | 18.0           |
| 14  | 6.0      | 2017-01-07  | 24.0           |
| o1  | 7.0      | 2017-01-01  | 31.0           |
| o2  | 20.0     | 2017-01-02  | 51.0           |
| o3  | 10.0     | 2017-01-02  | 61.0           |
| o4  | 40.0     | 2017-01-03  | 101.0          |
| o5  | 9.0      | 2017-01-04  | 110.0          |
| o6  | 5.0      | 2017-01-04  | 115.0          |
| o7  | 5.0      | 2017-01-05  | 120.0          |
| o8  | 4.0      | 2017-01-05  | 124.0          |
| o9  | 15.0     | 2017-01-05  | 139.0          |
+-----+----------+-------------+----------------+--+


To get running sum of groceries table - order by day:
----------------------------------------------------------

from groceries  select id, revenue, day,  sum(revenue) 
over (order by day rows between unbounded preceding and current row) as running_total;

Note: We can also avoid "rows between unbounded preceding and current row" as this is default settings.

+-----+----------+-------------+----------------+--+
| id  | revenue  |     day     | running_total  |
+-----+----------+-------------+----------------+--+
| o1  | 7.0      | 2017-01-01  | 7.0            |
| o2  | 20.0     | 2017-01-02  | 27.0           |
| o3  | 10.0     | 2017-01-02  | 37.0           |
| o4  | 40.0     | 2017-01-03  | 77.0           |
| o6  | 5.0      | 2017-01-04  | 82.0           |
| o5  | 9.0      | 2017-01-04  | 91.0           |
| o7  | 5.0      | 2017-01-05  | 96.0           |
| 11  | 5.0      | 2017-01-05  | 101.0          |
| o9  | 15.0     | 2017-01-05  | 116.0          |
| o8  | 4.0      | 2017-01-05  | 120.0          |
| 10  | 4.0      | 2017-01-06  | 124.0          |
| 12  | 4.0      | 2017-01-07  | 128.0          |
| 13  | 5.0      | 2017-01-07  | 133.0          |
| 14  | 6.0      | 2017-01-07  | 139.0          |
+-----+----------+-------------+----------------+--+

---------------OR---------------

select id, revenue, day,  sum(revenue) 
over (order by day rows between unbounded preceding and current row) as running_total 
from groceries;



To get running average of groceries table:
-------------------------------------------------------------------
select id, revenue, day,avg(revenue) 
over (order by id rows between unbounded preceding and current row) as running_average from groceries;
-----------------------------or-----------------------------------
select id, revenue, day,avg(revenue) 
over (order by id) as running_average from groceries;
+-----+----------+-------------+---------------------+--+
| id  | revenue  |     day     |   running_average   |
+-----+----------+-------------+---------------------+--+
| 10  | 4.0      | 2017-01-06  | 4.0                 |
| 11  | 5.0      | 2017-01-05  | 4.5                 |
| 12  | 4.0      | 2017-01-07  | 4.333333333333333   |
| 13  | 5.0      | 2017-01-07  | 4.5                 |
| 14  | 6.0      | 2017-01-07  | 4.8                 |
| o1  | 7.0      | 2017-01-01  | 5.166666666666667   |
| o2  | 20.0     | 2017-01-02  | 7.285714285714286   |
| o3  | 10.0     | 2017-01-02  | 7.625               |
| o4  | 40.0     | 2017-01-03  | 11.222222222222221  |
| o5  | 9.0      | 2017-01-04  | 11.0                |
| o6  | 5.0      | 2017-01-04  | 10.454545454545455  |
| o7  | 5.0      | 2017-01-05  | 10.0                |
| o8  | 4.0      | 2017-01-05  | 9.538461538461538   |
| o9  | 15.0     | 2017-01-05  | 9.928571428571429   |
+-----+----------+-------------+---------------------+--+

Calculate aggregations over a window on blocks of records
======================================================================


create table groceries1(id string,  
store string,  
product string,  
day date,  
revenue double) 
row format delimited 
fields terminated by ',';


load data local inpath  '/home/cloudera/Downloads/Hiveadv1/groceries1.csv' 
into table groceries1;


To get running revenue total for each day:
--------------------------------------------------
select id, revenue, day,  sum(revenue) 
over (partition by day  order by id) as running_total from groceries1;



To get running count of no of records for each day:
--------------------------------------------------------------

select id, revenue, day,count(id) 
over (  partition by day  order by id) as running_count from groceries1;

+-----+----------+-------------+----------------+--+
| id  | revenue  |     day     | running_count  |
+-----+----------+-------------+----------------+--+
| o1  | 7.0      | 2017-01-01  | 1              |
| o2  | 20.0     | 2017-01-02  | 1              |
| o3  | 10.0     | 2017-01-02  | 2              |
| o4  | 40.0     | 2017-01-03  | 1              |
| o5  | 9.0      | 2017-01-04  | 1              |
| o6  | 5.0      | 2017-01-04  | 2              |
| 11  | 5.0      | 2017-01-05  | 1              |
| o7  | 5.0      | 2017-01-05  | 2              |
| o8  | 4.0      | 2017-01-05  | 3              |
| o9  | 15.0     | 2017-01-05  | 4              |
| 10  | 4.0      | 2017-01-06  | 1              |
| 12  | 4.0      | 2017-01-07  | 1              |
| 13  | 5.0      | 2017-01-07  | 2              |
| 14  | 6.0      | 2017-01-07  | 3              |
+-----+----------+-------------+----------------+--+


select day,count(*) 
over (partition by day  order by id) as running_count from groceries1;



Revenue running total for each day without oredr bykeyspecified:
-------------------------------------------------------------------------------
select id, revenue, day,  sum(revenue) 
over (  partition by day  ) as running_sum from groceries1  ;




Moving Averages using a Window Function
==========================================================================

Calculating aggregations over a window of a specificsize:
-----------------------------------------------------------------------

select id, revenue, day,  avg(revenue) 
over (  order by id  rows between 3 preceding and current row) as running_average from groceries1;


select id, revenue, day,  sum(revenue) 
over (  order by id  rows between 3 preceding and current row) as running_average from groceries1;




Sorting in Hive
================================================================================
================================================================================

use trendytech;

create table order(order_id string, 
order_value int) 
row format delimited 
fields terminated by ',';

load data local inpath '/home/cloudera/Downloads/Hiveadv1/order.txt' into table order;

select * from order;

set hive.mapred.mode=nonstrict;

Order by 
-----------------------------------------------------------

select order_value from order order by order_value;


sort by
-----------------------------------------------------------

set hive.exec.reducers.bytes.per.reducer  -- Per reducer dividing work(MB)
set mapred.reduce.tasks = 2;   --- Setting no.of reducers to 2



select order_value from order sort by order_value;


Distribute by
------------------------------------------------------------------------

select order_value from order distribute by order_value;


Distribute by sort by
----------------------------------------------------------------------------

select order_value from order distribute by order_value sort by order_value;

Cluster by
---------------------------------------------------------------------------------

select order_value from order distribute by order_value;












